{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Assistente Virtual M√©dico com Whisper, LLaMA 3.1 e gTTS\n",
    "\n",
    "Este projeto √© um assistente virtual m√©dico que utiliza tecnologias de ponta para capturar √°udio, transcrever perguntas, gerar respostas usando um modelo de linguagem (LLaMA 3.1) e sintetizar a resposta em voz. O sistema √© projetado para ser executado localmente, utilizando Python 3.12 e o modelo LLaMA 3.1 8B instalado na sua m√°quina.\n",
    "\n",
    "---\n",
    "\n",
    "## Funcionalidades\n",
    "\n",
    "- **Captura de √Åudio em Tempo Real**: Captura √°udio do microfone usando a biblioteca `sounddevice`.\n",
    "- **Transcri√ß√£o de √Åudio**: Utiliza o modelo **Whisper tiny** da OpenAI para transcrever o √°udio em texto.\n",
    "- **Gera√ß√£o de Respostas**: Usa o modelo **LLaMA 3.1** (ou outro modelo menor) via **Ollama** para gerar respostas contextualizadas.\n",
    "- **S√≠ntese de Fala**: Converte a resposta gerada em voz usando a biblioteca **gTTS**.\n",
    "- **Loop de Intera√ß√£o Cont√≠nua**: O sistema funciona em um loop cont√≠nuo, permitindo intera√ß√µes sucessivas.\n",
    "\n",
    "---\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "- **Python 3.12**\n",
    "- **Modelo LLaMA 3.1 8B** instalado localmente via Ollama.\n",
    "- Depend√™ncias Python listadas no arquivo `requirements.txt`.\n",
    "\n",
    "---\n",
    "\n",
    "## Instala√ß√£o\n",
    "\n",
    "1. **Clone o reposit√≥rio**:\n",
    "   ```bash\n",
    "   git clone https://github.com/seu-usuario/assistente-virtual-medico.git\n",
    "   cd assistente-virtual-medico\n",
    "   ```\n",
    "\n",
    "2. **Crie um ambiente virtual** (opcional, mas recomendado):\n",
    "   ```bash\n",
    "   python -m venv .venv\n",
    "   source .venv/bin/activate  # Linux/macOS\n",
    "   .venv\\Scripts\\activate     # Windows\n",
    "   ```\n",
    "\n",
    "3. **Instale as depend√™ncias**:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "4. **Baixe o modelo Whisper tiny** (ser√° baixado automaticamente na primeira execu√ß√£o).\n",
    "\n",
    "5. **Instale o modelo LLaMA 3.1 via Ollama**:\n",
    "   ```bash\n",
    "   ollama pull llama3\n",
    "   ```\n",
    "\n",
    "6. **Instale o `mpg321`** (para reprodu√ß√£o de √°udio no Linux):\n",
    "   ```bash\n",
    "   sudo apt install mpg321\n",
    "   ```\n",
    "\n",
    "   No Windows, voc√™ pode usar outro player de √°udio compat√≠vel com a linha de comando.\n",
    "\n",
    "---\n",
    "\n",
    "## Como Executar\n",
    "\n",
    "1. **Execute o script**:\n",
    "   ```bash\n",
    "   python main.py\n",
    "   ```\n",
    "\n",
    "2. **Interaja com o assistente**:\n",
    "   - Fale ao microfone ap√≥s o prompt \"üéô Capturando √°udio...\".\n",
    "   - O assistente transcrever√° sua pergunta, gerar√° uma resposta e a reproduzir√° em voz alta.\n",
    "\n",
    "3. **Para interromper o programa**, pressione `Ctrl+C`.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura do C√≥digo\n",
    "\n",
    "- **capturar_audio**: Captura √°udio do microfone.\n",
    "- **transcrever_audio**: Transcreve o √°udio em texto usando Whisper.\n",
    "- **gerar_resposta**: Gera uma resposta usando o modelo LLaMA 3.1 via Ollama.\n",
    "- **falar_texto**: Converte a resposta em voz usando gTTS.\n",
    "- **Loop principal**: Gerencia a intera√ß√£o cont√≠nua com o usu√°rio.\n",
    "\n",
    "---\n",
    "\n",
    "## Depend√™ncias\n",
    "\n",
    "- **sounddevice**: Para captura de √°udio.\n",
    "- **whisper**: Para transcri√ß√£o de √°udio.\n",
    "- **gTTS**: Para s√≠ntese de fala.\n",
    "- **ollama**: Para intera√ß√£o com o modelo LLaMA 3.1.\n",
    "- **numpy**: Para manipula√ß√£o de √°udio.\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes\n",
    "\n",
    "- **Mem√≥ria RAM**: O modelo LLaMA 3.1 8B requer pelo menos 6-8 GB de RAM. Se o seu sistema tiver menos mem√≥ria, considere usar um modelo menor, como `llama2-7b` ou `llama3-7b`.\n",
    "- **Whisper Tiny**: O modelo `tiny` foi escolhido para reduzir o uso de mem√≥ria. Para maior precis√£o, voc√™ pode usar `base` ou `small`, mas isso exigir√° mais recursos.\n",
    "\n",
    "---\n",
    "\n",
    "## Licen√ßa\n",
    "\n",
    "Este projeto √© licenciado sob a [MIT License](LICENSE).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
